import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import cohen_kappa_score
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from lifelines import KaplanMeierFitter
import statsmodels.api as sm


# Configuration de la page
st.set_page_config(page_title="Mod√©lisation", page_icon="üß†", layout="wide")

@st.cache_data
def load_data():
    """Charge les donn√©es depuis un fichier Excel sans modifier le temps de suivi."""
    file_path = "Donnn√©es_Projet_M2SID2023_2024_pr√©par√©es.xlsx"
    df = pd.read_excel(file_path, engine="openpyxl")
    return df

# Charger les donn√©es
df = load_data()

st.title("üß† Modelisation")
st.write("Chargement et pr√©paration des donn√©es : Les donn√©es sont charg√©es, la variable cible Evolution est d√©finie, et les variables cat√©goriques sont encod√©es.")
st.write("Division des donn√©es : Les donn√©es sont s√©par√©es en ensembles d'entra√Ænement (80%) et de test (20%).")
st.write("S√©lection et param√©trage du mod√®le : L'utilisateur choisit entre une r√©gression logistique, un SVM ou une for√™t al√©atoire, avec des hyperparam√®tres ajustables.")
st.write("Entra√Ænement et √©valuation : Le mod√®le est entra√Æn√©, puis √©valu√© avec des m√©triques comme pr√©cision, rappel, F1-score, matrice de confusion et Kappa de Cohen.")
st.write("La m√©thode de Kaplan-Meier estime et affiche les courbes de survie et de d√©c√®s en fonction d'une variable explicative cat√©gorielle, permettant de comparer la probabilit√© de survie entre diff√©rents groupes.")

# V√©rifier si la colonne Evolution existe et la convertir
if "Evolution" in df.columns:
    if df["Evolution"].dtype == "object":
        df["Evolution"] = df["Evolution"].map({"Vivant": 1, "Deces": 0})
else:
    df["Evolution"] = pd.Series(dtype="float64")

# S√©parer les features et la cible
X = df.drop(columns=["Evolution"], errors="ignore")
y = df["Evolution"]

# S√©lectionner uniquement les colonnes cat√©goriques
categorical_cols = X.select_dtypes(include=["object"]).columns

# Convertir toutes les valeurs en cha√Ænes de caract√®res (√©vite l'erreur int/str mix√©s)
X[categorical_cols] = X[categorical_cols].astype(str)

# Encodage des variables cat√©goriques avec OneHotEncoder
encoder = OneHotEncoder(drop="first", sparse_output=False, handle_unknown="ignore")
X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]), 
                         columns=encoder.get_feature_names_out(), 
                         index=X.index)

# Fusionner avec les autres colonnes num√©riques
X_final = pd.concat([X_encoded, X.select_dtypes(exclude=["object"])], axis=1)

# Division en train/test
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)

# Barre lat√©rale pour choisir le mod√®le
st.sidebar.header("Param√®tres du mod√®le")
model_choice = st.sidebar.selectbox("Choisissez un mod√®le", ["R√©gression Logistique", "SVM", "For√™t Al√©atoire"])

if model_choice == "R√©gression Logistique":
    # Ajouter une constante pour l'interception
    X_train_sm = sm.add_constant(X_train)

    # Ajuster le mod√®le avec statsmodels
    logit_model = sm.Logit(y_train, X_train_sm)
    result = logit_model.fit()

    # Extraire les coefficients et calculer l'Odds Ratio
    odds_ratios = np.exp(result.params)

    # Extraire les p-values
    p_values = result.pvalues

    # Cr√©er un tableau des r√©sultats
    or_df = pd.DataFrame({
        "Variable": odds_ratios.index,
        "Odds Ratio": odds_ratios.values,
        "p-value": p_values.values
    })

    # Afficher les r√©sultats tri√©s par Odds Ratio
    st.write("### Rapport de cote (Odds Ratio) avec p-value")
    st.write(or_df.sort_values(by="Odds Ratio", ascending=False))


    c_value = st.sidebar.slider("C (Regularization)", 0.01, 10.0, 1.0)
    model = LogisticRegression(C=c_value)
elif model_choice == "SVM":
    kernel_type = st.sidebar.selectbox("Type de noyau", ["linear", "rbf", "poly", "sigmoid"])
    model = SVC(kernel=kernel_type)
else:
    n_estimators = st.sidebar.slider("Nombre d'arbres", 10, 200, 100)
    model = RandomForestClassifier(n_estimators=n_estimators)

# Entra√Ænement et √©valuation

if st.sidebar.button("Entra√Æner le mod√®le"):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    st.write("Classes r√©elles dans y_test :", y_test.value_counts())
    st.write("Pr√©dictions du mod√®le :", pd.Series(y_pred).value_counts())

    st.write("### √âvaluation du mod√®le")
    st.write(f"Pr√©cision : {accuracy_score(y_test, y_pred):.2f}")
    st.write(f"Score de pr√©cision : {precision_score(y_test, y_pred, average='weighted'):.2f}")
    st.write(f"Score de rappel : {recall_score(y_test, y_pred, average='weighted'):.2f}")
    st.write("Matrice de confusion :")
    st.write(confusion_matrix(y_test, y_pred))

    # Calcul du coefficient de Kappa
    kappa = cohen_kappa_score(y_test, y_pred)

    # Affichage du r√©sultat
    st.write(f"**Coefficient de Kappa de Cohen :** {kappa:.2f}")

# Kaplan-Meier 
st.sidebar.header("Kaplan-Meier")
variable_survie = "Nbj_Temps_Suivi_Apr√®s_Traitement"

# S√©lection des variables cat√©goriques
variables_categoriques = df.select_dtypes(include=["object", "category"]).columns.tolist()
variable_exp = st.sidebar.selectbox("Choisir une variable explicative", variables_categoriques)

if st.sidebar.button("Afficher Kaplan-Meier"):
    if variable_survie in df.columns and variable_exp in df.columns:
        
        # D√©finir les variables de suivi et d'√©v√©nement
        T = df[variable_survie]  
        E = df["Evolution"]  

        # V√©rifier qu'il y a bien plusieurs groupes
        valeurs_uniques = df[variable_exp].unique()
        if len(valeurs_uniques) > 1:
            kmf = KaplanMeierFitter()
            plt.figure(figsize=(10, 5))

            for val in valeurs_uniques:
                # Ajustement de la courbe de survie
                kmf.fit(T[df[variable_exp] == val], event_observed=E[df[variable_exp] == val], label=f"{variable_exp}={val}")
                
                # Tracer la courbe de survie
                kmf.plot_survival_function(label=f"Survie - {variable_exp}={val}")
                
                # Tracer la courbe de probabilit√© de d√©c√®s (1 - survie)
                plt.plot(kmf.survival_function_.index, 1 - kmf.survival_function_.iloc[:, 0], linestyle="dashed", label=f"D√©c√®s - {variable_exp}={val}")

            plt.xlabel("Temps de suivi")
            plt.ylabel("Probabilit√©")
            plt.title("Courbes de Kaplan-Meier (Survie et D√©c√®s)")
            plt.legend()
            st.pyplot(plt)
        else:
            st.warning(f"Pas assez de variations dans la variable {variable_exp} pour Kaplan-Meier.")
    else:
        st.error("Les variables s√©lectionn√©es ne sont pas valides.")
